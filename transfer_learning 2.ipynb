{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "In this Python notebook, we will be employing transfer learning techniques to train existing models (AlexNet, VGG, and DenseNet). The process will be divided into two main parts:\n",
    "\n",
    "Feature Extraction: In the first part, we will utilize the models as fixed feature extractors. This involves modifying only the last fully connected (FC) layer of each model to suit our specific task and training just this layer while keeping the rest of the model unchanged.\n",
    "\n",
    "Fine-Tuning: In the second part, we will implement fine-tuning, which involves training all the layers of the model on our dataset, starting from the pretrained weights. We will specifically apply this approach to AlexNet."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# pytorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import models, transforms\n",
    "import loralib as lora"
   ],
   "metadata": {
    "id": "8ohK6OWX87Ej",
    "ExecuteTime": {
     "end_time": "2024-03-22T11:41:51.222874Z",
     "start_time": "2024-03-22T11:41:51.218388Z"
    }
   },
   "execution_count": 133,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "r_JaO-xsyhJN",
    "ExecuteTime": {
     "end_time": "2024-03-22T11:41:52.839485Z",
     "start_time": "2024-03-22T11:41:52.834392Z"
    }
   },
   "outputs": [],
   "source": [
    "# create train dataloader and valid dataloader\n",
    "def set_transform():\n",
    "  train_transform = transforms.Compose([\n",
    "      transforms.RandomResizedCrop(224),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "  ])\n",
    "\n",
    "  valid_transform = transforms.Compose([\n",
    "      transforms.RandomResizedCrop(224),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "  ])\n",
    "\n",
    "  return train_transform, valid_transform\n",
    "\n",
    "def create_dataloader(root_dir, batch_size):\n",
    "  train_transform, valid_transform = set_transform()\n",
    "  # Create datasets\n",
    "  train_dataset = ImageFolder(root=root_dir + '/train', transform=train_transform)\n",
    "  valid_dataset = ImageFolder(root=root_dir + '/val', transform=valid_transform)\n",
    "  train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=2, shuffle=True)\n",
    "  valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, num_workers=2, shuffle=False)\n",
    "  dataloaders = {'train' : train_loader, 'val' : valid_loader}\n",
    "  return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting=False):\n",
    "    \"\"\"\n",
    "    Sets the .requires_grad attribute of the parameters in the model. This is used to freeze or unfreeze\n",
    "    the model's parameters during training.\n",
    "\n",
    "    Parameters:\n",
    "    - model (torch.nn.Module): The model whose parameters will be modified.\n",
    "    - feature_extracting (bool): If True, the model is being used for feature extraction, and all\n",
    "      parameters are frozen to prevent gradients from being computed. If False, the model will be fine-tuned,\n",
    "      and gradients will be computed for all parameters.\n",
    "\n",
    "    If feature_extracting is True, this function goes through all parameters in the model and sets\n",
    "    .requires_grad to False, effectively freezing the model during training. This is useful when you're only\n",
    "    interested in training a few top layers of a model while keeping the rest unchanged.\n",
    "\n",
    "    Conversely, if feature_extracting is False, this indicates that the model will undergo fine-tuning,\n",
    "    where all model parameters are subject to training. Therefore, it sets .requires_grad to True for all\n",
    "    parameters, allowing gradients to be computed and weights to be updated during training.\n",
    "    \"\"\"\n",
    "    if feature_extracting:\n",
    "        # Freeze all parameters for feature extraction\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    else:\n",
    "        # Unfreeze all parameters for fine-tuning\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n"
   ],
   "metadata": {
    "id": "B3yEnofB0rPN",
    "ExecuteTime": {
     "end_time": "2024-03-22T11:41:56.112920Z",
     "start_time": "2024-03-22T11:41:56.109521Z"
    }
   },
   "execution_count": 135,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True, set_lora=False):\n",
    "    \"\"\"\n",
    "    Initializes a model for transfer learning based on the specified architecture (model_name).\n",
    "    This function can adjust models for a new task by changing their output layers to match\n",
    "    the number of classes for the new task (num_classes). It supports operating in either\n",
    "    feature extraction or fine-tuning mode.\n",
    "\n",
    "    Parameters:\n",
    "    - model_name (str): The name of the model architecture to be initialized.\n",
    "    - num_classes (int): The number of classes for the new task.\n",
    "    - feature_extract (bool): If True, the model is set to feature extraction mode where only the final layer's parameters are updated.\n",
    "    - use_pretrained (bool): If True, initializes the model with weights pre-trained on ImageNet.\n",
    "    - set_lora (bool): Placeholder for future use, not implemented in this function.\n",
    "\n",
    "    Returns:\n",
    "    - model_ft (torch.nn.Module): The initialized model ready for training on the new task.\n",
    "    - input_size (int): The required input image size for the model, e.g., 224 for AlexNet.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize variables for the model and input size.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    # Define weights setting based on whether pretrained weights are desired.\n",
    "    weights = 'DEFAULT' if use_pretrained else None\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        # Initialize ResNet\n",
    "        model_ft = models.resnet18(weights=weights)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        # Initialize AlexNet\n",
    "        model_ft = models.alexnet(weights=weights)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features       \n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"vgg\":\n",
    "        # Initialize VGG\n",
    "        model_ft = models.vgg16(weights=weights)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        # Initialize SqueezeNet\n",
    "        model_ft = models.squeezenet1_0(weights=weights)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # SqueezeNet uses a Conv2d layer as its classifier.\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        # Initialize DenseNet\n",
    "        model_ft = models.densenet121(weights=weights)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        # Note: DenseNet's input size is often larger in practice, but 224 works for compatibility.\n",
    "        input_size = 224\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(\"The specified model name is not supported.\")\n",
    "\n",
    "    return model_ft, input_size"
   ],
   "metadata": {
    "id": "xS3JI_lW0CJg",
    "ExecuteTime": {
     "end_time": "2024-03-22T11:41:57.217921Z",
     "start_time": "2024-03-22T11:41:57.210216Z"
    }
   },
   "execution_count": 136,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def params_to_update(model, feature_extract):\n",
    "    \"\"\"\n",
    "    Identifies and returns the parameters to be optimized/updated in this run. If we are\n",
    "    fine-tuning, we will update all parameters. However, if we are using the feature extraction\n",
    "    method, we will only update the parameters that were recently initialized, i.e., the parameters\n",
    "    for which requires_grad is True.\n",
    "\n",
    "    Parameters:\n",
    "    - model (torch.nn.Module): The model for which parameters are to be identified.\n",
    "    - feature_extract (bool): Flag indicating whether we are feature extracting. If True, only parameters\n",
    "      that require gradients are updated; otherwise, all parameters are updated.\n",
    "\n",
    "    Returns:\n",
    "    - params_to_update (list of torch.nn.parameter.Parameter): A list of parameters that will be updated.\n",
    "    \"\"\"\n",
    "    if feature_extract:\n",
    "        params_to_update = []\n",
    "        print(\"Params to learn:\")\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                params_to_update.append(param)\n",
    "                print(\"\\t\", name)\n",
    "    else:\n",
    "        # In the case of fine-tuning, we consider all parameters for updates,\n",
    "        # but still filter them based on requires_grad to be consistent with the condition.\n",
    "        # This allows the function to be flexible for models where some parameters might explicitly be frozen.\n",
    "        params_to_update = [param for param in model.parameters() if param.requires_grad]\n",
    "        print(\"Params to learn:\")\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(\"\\t\", name)\n",
    "\n",
    "    return params_to_update\n"
   ],
   "metadata": {
    "id": "Ich73pbl37Jn",
    "ExecuteTime": {
     "end_time": "2024-03-22T11:41:59.823810Z",
     "start_time": "2024-03-22T11:41:59.820211Z"
    }
   },
   "execution_count": 137,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def train_model(model, model_name, dataloaders, criterion, optimizer, num_epochs=25, set_lora=False):\n",
    "    \"\"\"\n",
    "    Train and validate a PyTorch model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The model to be trained and validated.\n",
    "    - model_name: Name of the model, used for saving checkpoints.\n",
    "    - dataloaders: A dictionary containing 'train' and 'val' DataLoaders for loading the data.\n",
    "    - criterion: The loss function.\n",
    "    - optimizer: The optimization algorithm.\n",
    "    - num_epochs (int): The number of epochs to train the model.\n",
    "    - set_lora (bool): Flag for potential future use, not used in the current implementation.\n",
    "\n",
    "    Returns:\n",
    "    - model: The trained model.\n",
    "    - val_acc_history: A list with validation accuracy for each epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    # Store the original model parameters to restore later if needed.\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch goes through both training and validation phases\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data in batches.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                # Track history if in train phase\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # Backward pass and optimize if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            # Calculate epoch loss and accuracy\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Save the model if it has the best validation accuracy so far\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                results = [model_name, 'validation data', epoch, epoch_acc.item()]\n",
    "                val_acc_history.append(results)\n",
    "\n",
    "        print()\n",
    "\n",
    "    # Print out the training time and best validation accuracy\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "    # Load best model weights and save the model checkpoint\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    if not os.path.isdir('checkpoints'):\n",
    "        os.mkdir('checkpoints')\n",
    "    torch.save({'net': model.state_dict()}, f'./checkpoints/{model_name}.pth')\n",
    "\n",
    "    return model, val_acc_history\n"
   ],
   "metadata": {
    "id": "_hAAmM_Q17o9",
    "ExecuteTime": {
     "end_time": "2024-03-22T08:16:21.533472Z",
     "start_time": "2024-03-22T08:16:21.526388Z"
    }
   },
   "execution_count": 81,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def calculate_accuracy(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of a PyTorch model on a given dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - model (torch.nn.Module): The model to evaluate.\n",
    "    - dataloader (torch.utils.data.DataLoader): DataLoader for the dataset to evaluate the model on.\n",
    "    - device (torch.device): The device on which to perform the calculations (e.g., 'cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "    - model_accuracy (float): The accuracy of the model on the dataset as a percentage.\n",
    "    - confusion_matrix (np.array): A confusion matrix of size [num_classes, num_classes], where\n",
    "      num_classes is the number of unique labels in the dataset. The matrix is used to evaluate\n",
    "      the model's performance across different classes.\n",
    "    \"\"\"\n",
    "\n",
    "    # Switch the model to evaluation mode to deactivate Dropout and use learned statistics in BatchNorm.\n",
    "    model.eval()\n",
    "\n",
    "    total_correct = 0\n",
    "    total_images = 0\n",
    "    # Assuming a maximum of 38 classes - adjust the size according to your specific task.\n",
    "    confusion_matrix = np.zeros([38, 38], int)\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for efficiency\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass to get the model's predictions\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            # Update total images and correctly predicted counts\n",
    "            total_images += labels.size(0)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update confusion matrix\n",
    "            for i, l in enumerate(labels):\n",
    "                confusion_matrix[l.item(), predicted[i].item()] += 1\n",
    "\n",
    "    # Calculate accuracy as the percentage of correct predictions\n",
    "    model_accuracy = total_correct / total_images * 100\n",
    "\n",
    "    return model_accuracy, confusion_matrix"
   ],
   "metadata": {
    "id": "HkTj4clCD-bJ",
    "ExecuteTime": {
     "end_time": "2024-03-22T08:16:22.652910Z",
     "start_time": "2024-03-22T08:16:22.647783Z"
    }
   },
   "execution_count": 82,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=38, bias=True)\n",
      "  )\n",
      ")\n",
      "Params to learn:\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n",
      "using MPS\n",
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 1.2427 Acc: 0.6566\n",
      "val Loss: 0.6711 Acc: 0.7969\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 1.1103 Acc: 0.7071\n",
      "val Loss: 0.7150 Acc: 0.7970\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 1.0911 Acc: 0.7247\n",
      "val Loss: 0.5763 Acc: 0.8252\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 1.0823 Acc: 0.7298\n",
      "val Loss: 0.6467 Acc: 0.8125\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 1.0800 Acc: 0.7340\n",
      "val Loss: 0.5968 Acc: 0.8283\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 1.0803 Acc: 0.7378\n",
      "val Loss: 0.5773 Acc: 0.8310\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 1.0628 Acc: 0.7395\n",
      "val Loss: 0.5770 Acc: 0.8340\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 1.0777 Acc: 0.7396\n",
      "val Loss: 0.6015 Acc: 0.8304\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 1.0456 Acc: 0.7486\n",
      "val Loss: 0.5501 Acc: 0.8382\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 1.0800 Acc: 0.7445\n",
      "val Loss: 0.5569 Acc: 0.8442\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 1.0879 Acc: 0.7447\n",
      "val Loss: 0.5623 Acc: 0.8393\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 1.0640 Acc: 0.7493\n",
      "val Loss: 0.5343 Acc: 0.8493\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 1.0666 Acc: 0.7494\n",
      "val Loss: 0.6003 Acc: 0.8336\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 1.0626 Acc: 0.7535\n",
      "val Loss: 0.5437 Acc: 0.8449\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 1.0601 Acc: 0.7526\n",
      "val Loss: 0.5338 Acc: 0.8481\n",
      "\n",
      "Training complete in 230m 31s\n",
      "Best val Acc: 0.849277\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Main setup for running VGG as a feature extractor\n",
    "'''\n",
    "root_dir = r'/Users/noambuzaglo/Desktop/lilush/PlantVillage'\n",
    "batch_size = 4\n",
    "dataloaders = create_dataloader(root_dir, batch_size)\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet]\n",
    "model_name = \"vgg\"\n",
    "# Number of classes in the dataset\n",
    "num_classes = 38\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "# Number of epochs to train for\n",
    "num_epochs = 15\n",
    "# Flag for feature extracting. When False, we fine-tune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "params_to_update = params_to_update(model_ft)\n",
    "if torch.backends.mps.is_built():\n",
    "    print(\"using MPS\")\n",
    "    device = torch.device(\"mps\")\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "\n",
    "optimizer_ft = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "# Setup the loss fn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, model_name, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs)"
   ],
   "metadata": {
    "id": "-75G4zG032-v",
    "ExecuteTime": {
     "end_time": "2024-03-21T10:24:40.991814Z",
     "start_time": "2024-03-21T06:34:07.998291Z"
    }
   },
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "save validation result to CSV\n",
    "\"\"\" \n",
    "import csv\n",
    "filename = f\"results_{model_name}.csv\"\n",
    "with open (filename, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in hist:\n",
    "        writer.writerow(row)"
   ],
   "metadata": {
    "id": "urSZMYEY6a_Y",
    "ExecuteTime": {
     "end_time": "2024-03-21T10:25:05.786511Z",
     "start_time": "2024-03-21T10:25:05.728360Z"
    }
   },
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Evaluating the trained model on the test dataset reveals its accuracy and performance, offering insights into how well it generalizes to new, unseen data.\n",
    "\"\"\" \n",
    "test_transform = transforms.Compose([\n",
    "      transforms.RandomResizedCrop(224),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "  ])\n",
    "test_dataset = ImageFolder(root=root_dir + '/test', transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=2, shuffle=True)\n",
    "\n",
    "test_accuracy, _ = calculate_accuracy(model_ft, test_loader, device)\n",
    "print(f\"test accuracy:{test_accuracy}\")\n"
   ],
   "metadata": {
    "id": "Cq2x70BtAK4y",
    "ExecuteTime": {
     "end_time": "2024-03-21T10:30:14.620390Z",
     "start_time": "2024-03-21T10:28:58.520426Z"
    }
   },
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:84.75046210720888\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=38, bias=True)\n",
      "  )\n",
      ")\n",
      "Params to learn:\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n",
      "using MPS\n",
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 1.6758 Acc: 0.6963\n",
      "val Loss: 0.9980 Acc: 0.8095\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 1.5006 Acc: 0.7578\n",
      "val Loss: 0.8894 Acc: 0.8351\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 1.5135 Acc: 0.7674\n",
      "val Loss: 0.9347 Acc: 0.8324\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 1.4603 Acc: 0.7783\n",
      "val Loss: 0.9192 Acc: 0.8449\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 1.4604 Acc: 0.7875\n",
      "val Loss: 0.9050 Acc: 0.8458\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 1.4223 Acc: 0.7900\n",
      "val Loss: 1.0803 Acc: 0.8386\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 1.4374 Acc: 0.7904\n",
      "val Loss: 0.9248 Acc: 0.8578\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 1.4484 Acc: 0.7924\n",
      "val Loss: 0.9618 Acc: 0.8474\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 1.4446 Acc: 0.7971\n",
      "val Loss: 0.8594 Acc: 0.8628\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 1.4051 Acc: 0.8006\n",
      "val Loss: 0.9002 Acc: 0.8550\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 1.4269 Acc: 0.8014\n",
      "val Loss: 1.0303 Acc: 0.8483\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 1.4251 Acc: 0.8035\n",
      "val Loss: 0.8900 Acc: 0.8608\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 1.4065 Acc: 0.8067\n",
      "val Loss: 0.7230 Acc: 0.8812\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 1.4246 Acc: 0.8038\n",
      "val Loss: 0.8171 Acc: 0.8670\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 1.4154 Acc: 0.8075\n",
      "val Loss: 0.9923 Acc: 0.8531\n",
      "\n",
      "Training complete in 37m 36s\n",
      "Best val Acc: 0.881226\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Main setup for running alexnet as a feature extractor\n",
    "'''\n",
    "root_dir = r'/Users/noambuzaglo/Desktop/lilush/PlantVillage'\n",
    "batch_size = 4\n",
    "dataloaders = create_dataloader(root_dir, batch_size)\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet]\n",
    "model_name = \"alexnet\"\n",
    "# Number of classes in the dataset\n",
    "num_classes = 38\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "# Number of epochs to train for\n",
    "num_epochs = 15\n",
    "# Flag for feature extracting. When False, we fine-tune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "params_to_update = params_to_update(model_ft)\n",
    "if torch.backends.mps.is_built():\n",
    "    print(\"using MPS\")\n",
    "    device = torch.device(\"mps\")\n",
    "model_ft = model_ft.to(device)\n",
    "optimizer_ft = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "##%%\n",
    "# Setup the loss fn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, model_name, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T11:11:47.610665Z",
     "start_time": "2024-03-21T10:34:10.596847Z"
    }
   },
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:84.84288354898337\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "save validation result to CSV\n",
    "\"\"\" \n",
    "\n",
    "filename = f\"results_{model_name}.csv\"\n",
    "with open (filename, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in hist:\n",
    "        writer.writerow(row)\n",
    "\"\"\"\n",
    "Evaluating the trained model on the test dataset reveals its accuracy and performance, offering insights into how well it generalizes to new, unseen data.\n",
    "\"\"\" \n",
    "test_accuracy, _ = calculate_accuracy(model_ft, test_loader, device)\n",
    "print(f\"test accuracy:{test_accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T11:12:47.490526Z",
     "start_time": "2024-03-21T11:12:26.231603Z"
    }
   },
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace=True)\n",
      "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition(\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition(\n",
      "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1024, out_features=38, bias=True)\n",
      ")\n",
      "Params to learn:\n",
      "\t classifier.weight\n",
      "\t classifier.bias\n",
      "using MPS\n",
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 1.2229 Acc: 0.6635\n",
      "val Loss: 0.4935 Acc: 0.8592\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.8422 Acc: 0.7553\n",
      "val Loss: 0.4447 Acc: 0.8696\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.7802 Acc: 0.7736\n",
      "val Loss: 0.4333 Acc: 0.8672\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.7503 Acc: 0.7794\n",
      "val Loss: 0.3882 Acc: 0.8856\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.7294 Acc: 0.7869\n",
      "val Loss: 0.4343 Acc: 0.8688\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.7268 Acc: 0.7887\n",
      "val Loss: 0.3940 Acc: 0.8826\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.7108 Acc: 0.7925\n",
      "val Loss: 0.4250 Acc: 0.8734\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.7012 Acc: 0.7943\n",
      "val Loss: 0.3687 Acc: 0.8888\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.6897 Acc: 0.7983\n",
      "val Loss: 0.3870 Acc: 0.8822\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.6952 Acc: 0.7965\n",
      "val Loss: 0.3871 Acc: 0.8818\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.6959 Acc: 0.7946\n",
      "val Loss: 0.4007 Acc: 0.8806\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.6786 Acc: 0.7997\n",
      "val Loss: 0.3796 Acc: 0.8907\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.6771 Acc: 0.7996\n",
      "val Loss: 0.4016 Acc: 0.8786\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.6855 Acc: 0.8010\n",
      "val Loss: 0.3835 Acc: 0.8861\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.6703 Acc: 0.8028\n",
      "val Loss: 0.3698 Acc: 0.8902\n",
      "\n",
      "Training complete in 196m 11s\n",
      "Best val Acc: 0.890710\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Main setup for running densenet as a feature extractor\n",
    "'''\n",
    "root_dir = r'/Users/noambuzaglo/Desktop/lilush/PlantVillage'\n",
    "batch_size = 4\n",
    "dataloaders = create_dataloader(root_dir, batch_size)\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet]\n",
    "model_name = \"densenet\"\n",
    "# Number of classes in the dataset\n",
    "num_classes = 38\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8 \n",
    "# Number of epochs to train for\n",
    "num_epochs = 15\n",
    "# Flag for feature extracting. When False, we fine-tune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "params_to_update = params_to_update(model_ft)\n",
    "if torch.backends.mps.is_built():\n",
    "    print(\"using MPS\")\n",
    "    device = torch.device(\"mps\")\n",
    "model_ft = model_ft.to(device)\n",
    "optimizer_ft = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "##%%\n",
    "# Setup the loss fn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, model_name, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T19:55:04.281291Z",
     "start_time": "2024-03-21T16:38:51.935591Z"
    }
   },
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:88.56284658040666\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "save validation result to CSV\n",
    "\"\"\" \n",
    "filename = f\"results_{model_name}.csv\"\n",
    "with open (filename, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in hist:\n",
    "        writer.writerow(row)\n",
    "\n",
    "\"\"\"\n",
    "Evaluating the trained model on the test dataset reveals its accuracy and performance, offering insights into how well it generalizes to new, unseen data.\n",
    "\"\"\" \n",
    "test_accuracy, _ = calculate_accuracy(model_ft, test_loader, device)\n",
    "print(f\"test accuracy:{test_accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T22:07:00.900098Z",
     "start_time": "2024-03-21T22:06:08.863369Z"
    }
   },
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=38, bias=True)\n",
      "  )\n",
      ")\n",
      "using MPS\n",
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.8063 Acc: 0.7692\n",
      "val Loss: 0.3476 Acc: 0.8916\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.3441 Acc: 0.8918\n",
      "val Loss: 0.2255 Acc: 0.9277\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.2698 Acc: 0.9141\n",
      "val Loss: 0.1930 Acc: 0.9373\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.2275 Acc: 0.9261\n",
      "val Loss: 0.1901 Acc: 0.9392\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.2039 Acc: 0.9338\n",
      "val Loss: 0.1801 Acc: 0.9417\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.1839 Acc: 0.9402\n",
      "val Loss: 0.1362 Acc: 0.9582\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.1723 Acc: 0.9426\n",
      "val Loss: 0.1515 Acc: 0.9508\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.1550 Acc: 0.9488\n",
      "val Loss: 0.1383 Acc: 0.9569\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.1491 Acc: 0.9513\n",
      "val Loss: 0.1174 Acc: 0.9621\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.1382 Acc: 0.9551\n",
      "val Loss: 0.1205 Acc: 0.9614\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.1321 Acc: 0.9569\n",
      "val Loss: 0.1215 Acc: 0.9606\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.1271 Acc: 0.9583\n",
      "val Loss: 0.1141 Acc: 0.9645\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.1205 Acc: 0.9604\n",
      "val Loss: 0.1104 Acc: 0.9656\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.1176 Acc: 0.9611\n",
      "val Loss: 0.1087 Acc: 0.9655\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.1127 Acc: 0.9628\n",
      "val Loss: 0.1144 Acc: 0.9616\n",
      "\n",
      "Training complete in 50m 22s\n",
      "Best val Acc: 0.965565\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Main setup for running alexnet as a fine-tuning\n",
    "'''\n",
    "root_dir = r'/Users/noambuzaglo/Desktop/lilush/PlantVillage'\n",
    "batch_size = 128\n",
    "dataloaders = create_dataloader(root_dir, batch_size)\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet]\n",
    "model_name = \"alexnet\"\n",
    "# Number of classes in the dataset\n",
    "num_classes = 38\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 32\n",
    "# Number of epochs to train for\n",
    "num_epochs = 15\n",
    "# Flag for feature extracting. When False, we fine-tune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = False\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.backends.mps.is_built():\n",
    "    print(\"using MPS\")\n",
    "    device = torch.device(\"mps\")\n",
    "model_ft = model_ft.to(device)\n",
    "optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "##%%\n",
    "# Setup the loss fn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Train and evaluate\n",
    "model_name = 'alexnet_fine_tune'\n",
    "model_ft, hist = train_model(model_ft, model_name, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:19:08.660329Z",
     "start_time": "2024-03-21T15:28:44.036534Z"
    }
   },
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:96.85767097966729\n"
     ]
    }
   ],
   "source": [
    "filename = f\"results_{model_name}.csv\"\n",
    "with open (filename, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in hist:\n",
    "        writer.writerow(row)\n",
    "\n",
    "test_accuracy, _ = calculate_accuracy(model_ft, test_loader, device)\n",
    "print(f\"test accuracy:{test_accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:19:50.189592Z",
     "start_time": "2024-03-21T16:19:27.052046Z"
    }
   },
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=38, bias=True)\n",
      "  )\n",
      ")\n",
      "using MPS\n",
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 3.5490 Acc: 0.0965\n",
      "val Loss: 3.3453 Acc: 0.0985\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 3.2738 Acc: 0.1218\n",
      "val Loss: 3.1537 Acc: 0.1839\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Main setup for running alexnet as a fine-tuning\n",
    "'''\n",
    "root_dir = r'/Users/noambuzaglo/Desktop/lilush/PlantVillage'\n",
    "batch_size = 128\n",
    "dataloaders = create_dataloader(root_dir, batch_size)\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet]\n",
    "model_name = \"alexnet\"\n",
    "# Number of classes in the dataset\n",
    "num_classes = 38\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 32\n",
    "# Number of epochs to train for\n",
    "num_epochs = 15\n",
    "# Flag for feature extracting. When False, we fine-tune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = False\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=False)\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.backends.mps.is_built():\n",
    "    print(\"using MPS\")\n",
    "    device = torch.device(\"mps\")\n",
    "model_ft = model_ft.to(device)\n",
    "optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "##%%\n",
    "# Setup the loss fn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Train and evaluate\n",
    "model_name = 'alexnet_fine_tune_with_weights'\n",
    "model_ft, hist = train_model(model_ft, model_name, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-03-22T13:37:01.773630Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "from here start lora part"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t classifier.6.bias\n",
      "\t classifier.6.lora_A\n",
      "\t classifier.6.lora_B\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.alexnet(weights='DEFAULT')\n",
    "set_parameter_requires_grad(model_ft, True)\n",
    "num_ftrs = model_ft.classifier[6].in_features\n",
    "model_ft.classifier[6] = lora.Linear(num_ftrs, 38, 16)\n",
    "# Your custom classifier\n",
    "# Assuming num_classes is the number of output classes you have\n",
    "\n",
    "for name,param in model_ft.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "              print(\"\\t\",name)\n",
    "\n",
    "lora.mark_only_lora_as_trainable(model_ft)\n",
    "params_to_update = []  # override the initial list definition above\n",
    "for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "optimizer = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T11:45:16.777655Z",
     "start_time": "2024-03-22T11:45:16.210113Z"
    }
   },
   "execution_count": 138
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using MPS\n",
      "\t classifier.6.lora_A\n",
      "\t classifier.6.lora_B\n",
      "\t classifier.6.lora_A\n",
      "\t classifier.6.lora_B\n",
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 3.2468 Acc: 0.1732\n",
      "val Loss: 2.5228 Acc: 0.3287\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 2.1291 Acc: 0.4092\n",
      "val Loss: 1.6984 Acc: 0.5047\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 1.5662 Acc: 0.5399\n",
      "val Loss: 1.2964 Acc: 0.6109\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 1.2600 Acc: 0.6211\n",
      "val Loss: 1.0397 Acc: 0.6895\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 1.0818 Acc: 0.6735\n",
      "val Loss: 0.9020 Acc: 0.7269\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.9911 Acc: 0.6983\n",
      "val Loss: 0.8077 Acc: 0.7582\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.9191 Acc: 0.7188\n",
      "val Loss: 0.7578 Acc: 0.7691\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.8636 Acc: 0.7354\n",
      "val Loss: 0.7208 Acc: 0.7793\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.8286 Acc: 0.7447\n",
      "val Loss: 0.6704 Acc: 0.7956\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.7908 Acc: 0.7579\n",
      "val Loss: 0.6353 Acc: 0.8046\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.7569 Acc: 0.7654\n",
      "val Loss: 0.6275 Acc: 0.8054\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.7397 Acc: 0.7735\n",
      "val Loss: 0.5781 Acc: 0.8260\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.7259 Acc: 0.7742\n",
      "val Loss: 0.5681 Acc: 0.8259\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.7077 Acc: 0.7816\n",
      "val Loss: 0.5415 Acc: 0.8313\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.6872 Acc: 0.7871\n",
      "val Loss: 0.5296 Acc: 0.8361\n",
      "\n",
      "Training complete in 29m 21s\n",
      "Best val Acc: 0.836111\n"
     ]
    }
   ],
   "source": [
    "# main code:\n",
    "root_dir = r'/Users/noambuzaglo/Desktop/lilush/PlantVillage'\n",
    "batch_size = 128\n",
    "dataloaders = create_dataloader(root_dir, batch_size)\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet]\n",
    "model_name = \"alexnet\"\n",
    "# Number of classes in the dataset\n",
    "num_classes = 38\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 32\n",
    "# Number of epochs to train for\n",
    "num_epochs = 15\n",
    "# Flag for feature extracting. When False, we fine-tune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True\n",
    "# model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True, set_lora=True)\n",
    "# Print the model we just instantiated\n",
    "# print(model_ft)\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# params_to_update = params_to_update(model_ft)\n",
    "if torch.backends.mps.is_built():\n",
    "    print(\"using MPS\")\n",
    "    device = torch.device(\"mps\")\n",
    "model_ft = model_ft.to(device)\n",
    "optimizer_ft = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "##%%\n",
    "# Setup the loss fn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Train and evaluate\n",
    "model_name = 'alexnet22'\n",
    "model_ft, hist = train_model(model_ft, model_name, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs, set_lora=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T12:14:40.345654Z",
     "start_time": "2024-03-22T11:45:17.801947Z"
    }
   },
   "execution_count": 139
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using MPS\n",
      "\t classifier.6.lora_A\n",
      "\t classifier.6.lora_B\n",
      "\t classifier.6.lora_A\n",
      "\t classifier.6.lora_B\n",
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.6784 Acc: 0.7886\n",
      "val Loss: 0.5005 Acc: 0.8486\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.6585 Acc: 0.7965\n",
      "val Loss: 0.4884 Acc: 0.8494\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.6437 Acc: 0.7990\n",
      "val Loss: 0.4909 Acc: 0.8473\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.6342 Acc: 0.8025\n",
      "val Loss: 0.4617 Acc: 0.8566\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.6254 Acc: 0.8036\n",
      "val Loss: 0.4709 Acc: 0.8526\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.6126 Acc: 0.8079\n",
      "val Loss: 0.4643 Acc: 0.8611\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.6084 Acc: 0.8102\n",
      "val Loss: 0.4432 Acc: 0.8593\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.6016 Acc: 0.8115\n",
      "val Loss: 0.4430 Acc: 0.8604\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.5837 Acc: 0.8166\n",
      "val Loss: 0.4314 Acc: 0.8658\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.5834 Acc: 0.8158\n",
      "val Loss: 0.4240 Acc: 0.8690\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.5737 Acc: 0.8193\n",
      "val Loss: 0.4136 Acc: 0.8702\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.5720 Acc: 0.8204\n",
      "val Loss: 0.4184 Acc: 0.8697\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.5646 Acc: 0.8207\n",
      "val Loss: 0.4320 Acc: 0.8670\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.5653 Acc: 0.8205\n",
      "val Loss: 0.3962 Acc: 0.8758\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.5629 Acc: 0.8205\n",
      "val Loss: 0.3955 Acc: 0.8798\n",
      "\n",
      "Training complete in 38m 26s\n",
      "Best val Acc: 0.879845\n"
     ]
    }
   ],
   "source": [
    "# main code:\n",
    "root_dir = r'/Users/noambuzaglo/Desktop/lilush/PlantVillage'\n",
    "batch_size = 4\n",
    "dataloaders = create_dataloader(root_dir, batch_size)\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet]\n",
    "model_name = \"alexnet\"\n",
    "# Number of classes in the dataset\n",
    "num_classes = 38\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "# Number of epochs to train for\n",
    "num_epochs = 15\n",
    "# Flag for feature extracting. When False, we fine-tune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True\n",
    "# model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True, set_lora=True)\n",
    "# Print the model we just instantiated\n",
    "# print(model_ft)\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# params_to_update = params_to_update(model_ft)\n",
    "if torch.backends.mps.is_built():\n",
    "    print(\"using MPS\")\n",
    "    device = torch.device(\"mps\")\n",
    "model_ft = model_ft.to(device)\n",
    "optimizer_ft = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "##%%\n",
    "# Setup the loss fn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Train and evaluate\n",
    "model_name = 'alexnet23'\n",
    "model_ft, hist = train_model(model_ft, model_name, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs, set_lora=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T12:53:17.358030Z",
     "start_time": "2024-03-22T12:14:50.752710Z"
    }
   },
   "execution_count": 140
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:88.1931608133087\n"
     ]
    }
   ],
   "source": [
    "test_transform = transforms.Compose([\n",
    "      transforms.RandomResizedCrop(224),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "  ])\n",
    "test_dataset = ImageFolder(root=root_dir + '/test', transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=2, shuffle=True)\n",
    "\n",
    "test_accuracy, _ = calculate_accuracy(model_ft, test_loader, device)\n",
    "print(f\"test accuracy:{test_accuracy}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T12:53:50.491763Z",
     "start_time": "2024-03-22T12:53:28.209701Z"
    }
   },
   "execution_count": 141
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
